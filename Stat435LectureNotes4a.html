<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Xiongzhi Chen" />
  <meta name="author" content="Washington State University" />
  <title>Stat 435 Lecture Notes 4a</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/reveal.css"/>



<link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/theme/simple.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>


<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

    <link href="libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
</head>
<body>
<style type="text/css">
p { 
  text-align: left; 
  }
.reveal pre code { 
  color: #000000; 
  background-color: rgb(240,240,240);
  font-size: 1.15em;
  border:none; 
  }
.reveal section img { 
  background:none; 
  border:none; 
  box-shadow:none;
  height: 500px;
  }
}
</style>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Stat 435 Lecture Notes 4a</h1>
    <h2 class="author">Xiongzhi Chen</h2>
    <h2 class="author">Washington State University</h2>
</section>

<section><section id="section" class="titleslide slide level1"><h1><img src="howto.jpg"></img></h1></section></section>
<section><section id="model-assessment" class="titleslide slide level1"><h1>Model assessment</h1></section><section id="model-and-estimate" class="slide level2">
<h1>Model and estimate</h1>
<ul>
<li>Model: <span class="math inline">\(Y=\beta_0+\beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_p X_p + \varepsilon\)</span></li>
<li>Observations: <span class="math inline">\(\mathbf{z}_i=(y_i,x_{i1},x_{i2},\ldots,x_{ip}),i=1,\ldots,n\)</span>, where <span class="math inline">\(y_i\)</span> is the <span class="math inline">\(i\)</span>th observation for <span class="math inline">\(Y\)</span> and <span class="math inline">\(x_{ij}\)</span> that for <span class="math inline">\(X_j\)</span></li>
<li>Estimate <span class="math inline">\(\hat{\boldsymbol{\beta}}=(\hat{\beta}_0,\hat{\beta}_1,\ldots,\hat{\beta}_p)\)</span> of <span class="math inline">\({\boldsymbol{\beta}}=({\beta}_0,{\beta}_1,\ldots,{\beta}_p)\)</span></li>
<li>Fitted model: <span class="math inline">\(\hat{y}_i=\hat{\beta}_0+\hat{\beta}_1 x_{i1} + \hat{\beta}_2 x_{i2} + \ldots + \hat{\beta}_p x_{ip}\)</span></li>
<li>Residuals: <span class="math inline">\(e_i=y_i - \hat{y}_i\)</span></li>
</ul>
<p><em>Note:</em> there are many ways to obtain an estimate <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> of <span class="math inline">\({\boldsymbol{\beta}}\)</span></p>
</section><section id="training-error" class="slide level2">
<h1>Training error</h1>
<ul>
<li><p><em>Training error</em> is a measure on the performance of a model when it is fitted/trained from a set of observations that we call the <em>training set</em>. Namely, <em>training error measures how well a fitted/trained model fits/learns the training set</em>.</p></li>
<li><p>A commonly used training error is the <em>residual sum of squares (RSS)</em> (though other choices are available)</p></li>
<li><p>For example, if we take the set of <span class="math inline">\(n\)</span> observations as the training set and use RSS as the training error, then the <em>least squares estimate (LSE)</em> minimizes <span class="math inline">\(\textrm{RSS}=\sum_{i=1}^m e_i^2\)</span></p></li>
</ul>
</section><section id="test-error" class="slide level2">
<h1>Test error</h1>
<ul>
<li><em>Test error</em> is a measure on the <em>predictive performance</em> of a (fitted/trained) model when it is used to predict the responses of new observations on the predictors <span class="math inline">\(\tilde{X}=(X_1,\ldots,X_p)\)</span> that are not in the training set (that is used to fit/train the model). Namely, <em>test error measures how well a fitted/trained model predicts responses for observations that are not part of a training set</em>.</li>
<li>For example, given a new observation <span class="math inline">\(\mathbf{x}_0=(x_{01},x_{02},\ldots,x_{0p})\)</span> for <span class="math inline">\(\tilde{X}\)</span>, let <span class="math inline">\(y_0\)</span> be the predicted response given by the fitted/trained model. Then we can use <span class="math inline">\(E(y_0 -\hat{y}_0)^2\)</span> as the test error.</li>
</ul>
<p><em>Note:</em> other measures of test error are available</p>
</section><section id="training-error-and-test-error" class="slide level2">
<h1>Training error and test error</h1>
<ul>
<li>Training error measures how well a fitted/trained model fits/learns the <em>seen</em> observations (of the training set), whereas test error measures how well this model <em>predicts unseen responses</em> based on unseen observations on predictors</li>
<li><em>Test error is alway unknown and needs to be estimated</em></li>
<li>A model that has good predictive performance is referred to as having good “generalization performance” or “generalizes well”</li>
<li>A model that fits the training set very well or perfectly is often referred to as “overfitting” or “overfits”</li>
</ul>
</section><section id="training-error-and-test-error-1" class="slide level2">
<h1>Training error and test error</h1>
<ul>
<li>Classic wisdom: it is believed that an overfitting model that fits the training set very well or perfectly (i.e., with very small training error) cannot generalize well (i.e., cannot have small testing error)</li>
<li>Modern wisdom: when there are relatively few parameters in the model, the classic wisdom is sensible. However, beyond a critical setting, an overfitting model (with many parameters) can have very good generalization performance.</li>
</ul>
<p><em>Note:</em> Modern wisdom, dubbed as the “<strong>double descent curve</strong>”, was discovered by Dr. Belkin and his coauthors</p>
</section><section id="double-descent-curve" class="slide level2">
<h1>Double descent curve</h1>
<p><img src="doubledescent.png" width="85%" style="display: block; margin: auto;" /></p>
<p><em>Image credit:</em> Belkin et al; doi.org/10.1073/pnas.1903070116</p>
</section></section>
<section><section id="cross-validation" class="titleslide slide level1"><h1>Cross-validation</h1></section><section id="overview" class="slide level2">
<h1>Overview</h1>
<p><em>Cross-validation is a resampling technique to estimate test error</em>, and is often implemented as follows:</p>
<ul>
<li>Randomly divides a set of observations into a <em>training set</em> and <em>validation set</em></li>
<li>Use the training set to fit a model (that optimizes some <em>training error</em>), and apply the fitted model to predict the responses for the observations in the validation set to obtain an estimate of the <em>test error</em> of the model</li>
<li>Do the above independently for different random splits, and estimate test error from the estimates of test error</li>
</ul>
</section><section id="pictorial-description" class="slide level2">
<h1>Pictorial description</h1>
<p><img src="fig5_1.png" width="90%" style="display: block; margin: auto;" /></p>
</section><section id="cv-estimate-test-error" class="slide level2">
<h1>CV: estimate test error</h1>
<p>With <span class="math inline">\(n\)</span> observations <span class="math inline">\(\mathbf{z}_i = (y_i,\mathbf{x}_i)\)</span>,</p>
<ul>
<li><p>Randomly split the <span class="math inline">\(n\)</span> observations into a training set <span class="math inline">\(\mathcal{T}_1\)</span> with <span class="math inline">\(n_1\)</span> observations, and a validation set <span class="math inline">\(\mathcal{V}_1\)</span> with <span class="math inline">\(n_2=n-n_1\)</span> observations</p></li>
<li><p>Fit model <span class="math inline">\(M_l\)</span> using <span class="math inline">\(\mathcal{T}\)</span>, apply fitted model <span class="math inline">\(\hat{M}_l\)</span> to predict responses in <span class="math inline">\(\mathcal{V}_1\)</span>, and compute the <em>mean squared error (MSE)</em> <span class="math display">\[\textrm{MSE}(\mathcal{V}_1)=n_2^{-1} \sum_{y_i \in \mathcal{V}_1} (y_i -\hat{y}_i)^2,\]</span> where <span class="math inline">\(\hat{y}_i\)</span> is the fitted value for <span class="math inline">\(y_i\)</span></p></li>
</ul>
<p><em>Note:</em> <span class="math inline">\(\mathcal{T}_1\)</span> and <span class="math inline">\(\mathcal{V}_1\)</span> are disjoint</p>
</section><section id="cv-estimate-test-error-1" class="slide level2">
<h1>CV: estimate test error</h1>
<ul>
<li>Repeat the above “splitting-training-validating” steps independently <span class="math inline">\(k\)</span> times for model <span class="math inline">\(M_l\)</span> to obtain <span class="math inline">\(k\)</span> MSE’s <span class="math inline">\(\textrm{MSE}(\mathcal{V}_j),j=1,\ldots,k\)</span>, and estimate the test <em>mean squared error (MSE)</em> of model <span class="math inline">\(M_l\)</span> by <span class="math display">\[\textrm{CV}(M_l)=k^{-1} \sum_{j=1}^k \textrm{MSE}(\mathcal{V}_j)\]</span></li>
</ul>
<p><em>Note:</em> the above steps give an estimate of test error of model <span class="math inline">\(M_l\)</span></p>
</section><section id="cv-model-selection" class="slide level2">
<h1>CV: model selection</h1>
<ul>
<li>Obtain via cross-validation the estimated test error for each model <span class="math inline">\(M_l,l=1,\ldots,L\)</span></li>
<li>Pick the model that has the smallest estimated test MSE, i.e., pick the optimal model <span class="math inline">\(M^{\ast}\)</span> such that <span class="math display">\[\textrm{CV}(M^*)=\min_{1\le l \le L}\textrm{CV}(M_l)\]</span></li>
</ul>
<p><em>Note:</em> the above gives the best model among a set of models</p>
</section><section id="illustration" class="slide level2">
<h1>Illustration</h1>
<p><img src="fig5_2.png" width="90%" style="display: block; margin: auto;" /></p>
</section><section id="k-fold-cross-validation" class="slide level2">
<h1><span class="math inline">\(k\)</span>-fold cross-validation</h1>
<p>The <span class="math inline">\(k\)</span>-fold CV for model <span class="math inline">\(M_l\)</span> is implemented as follows:</p>
<ul>
<li>Randomly splits the data set into <span class="math inline">\(k\)</span> groups, or “folds”, of approximately equal sizes</li>
<li>Pick a fold, say, folder <span class="math inline">\(j\)</span>, as the validation set (i.e., the “held-out” fold), fit the model on the remaining <span class="math inline">\(k-1\)</span> folds, and compute the mean squared error, <span class="math inline">\(\textrm{MSE}_{j}\)</span>, on the observations in the held-out fold</li>
<li>Do the above for all <span class="math inline">\(j,j=1,\ldots,k\)</span>, and estimate the test MSE of the model by <span class="math display">\[
\textrm{CV}({M_l})=\frac{1}{k}\sum_{j=1}^{k}\textrm{MSE}_{j}
\]</span></li>
</ul>
</section></section>
<section><section id="variable-and-model-selection" class="titleslide slide level1"><h1>Variable and model selection</h1></section><section id="motivation" class="slide level2">
<h1>Motivation</h1>
<p>Settings:</p>
<ul>
<li><p>Model: <span class="math inline">\(Y=\beta_0+\beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_p X_p + \varepsilon\)</span></p></li>
<li><p>Observations: <span class="math inline">\((y_i,x_{i1},x_{i2},\ldots,x_{ip}),i=1,\ldots,n\)</span>, where <span class="math inline">\(y_i\)</span> is the <span class="math inline">\(i\)</span>th observation for <span class="math inline">\(Y\)</span> and <span class="math inline">\(x_{ij}\)</span> that for <span class="math inline">\(X_j\)</span></p></li>
<li><p>Estimate <span class="math inline">\(\hat{\boldsymbol{\beta}}=(\hat{\beta}_0,\hat{\beta}_1,\ldots,\hat{\beta}_p)\)</span> of <span class="math inline">\({\boldsymbol{\beta}}=({\beta}_0,{\beta}_1,\ldots,{\beta}_p)\)</span></p></li>
</ul>
<p><em>How to obtain an estimate <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> of <span class="math inline">\({\boldsymbol{\beta}}\)</span> depends critically on</em></p>
<ul>
<li>the relative magnitudes of <span class="math inline">\(p+1\)</span> and <span class="math inline">\(n\)</span></li>
<li>what properties we want <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> to have</li>
</ul>
</section><section id="classic-scenario-p1-le-n" class="slide level2">
<h1>Classic scenario: <span class="math inline">\(p+1 \le n\)</span></h1>
<p>When the number of parameters is not larger than the sample size:</p>
<ul>
<li>The <em>least squares estimate (LSE)</em> is <em>uniquely</em> defined</li>
<li>The LSE is unbiased, i.e., <span class="math inline">\(E(\hat{\boldsymbol{\beta}})={\boldsymbol{\beta}}\)</span>, when <span class="math inline">\(E(\varepsilon)=0\)</span></li>
<li>The LSE is optimal in some sense (e.g., Gauss-Markov theorem, meaning that the LSE has the smallest variance among all linear unbiased estimators, if the random errors are uncorrelated and have equal variances and zero expectation)</li>
</ul>
</section><section id="classic-scenario-p1-le-n-1" class="slide level2">
<h1>Classic scenario: <span class="math inline">\(p+1 \le n\)</span></h1>
<p>When the number of parameters is not larger than the sample size but <em>there are many potential predictors</em>, we often desire a <em>small</em> model that is easy to interpret and perform well. Namely, we still need to consider:</p>
<ul>
<li>Which predictors are the <em>most relevant</em> to the response</li>
<li>how to build a <em>small</em> model using a few predictors that can well predict the response</li>
</ul>
<p><em>Variable or model selection is needed in the classic scenario when there are many potential predictors.</em></p>
</section><section id="modern-scenario-p1-n" class="slide level2">
<h1>Modern scenario: <span class="math inline">\(p+1 &gt; n\)</span></h1>
<p>When the number of parameters is bigger than the sample size,</p>
<ul>
<li>The LSE is <em>not uniquely</em> defined, i.e., there are infinitely many models that minimizes the residual sum of squares</li>
<li>An LSE is biased in general, i.e., <span class="math inline">\(E(\hat{\boldsymbol{\beta}}) \ne {\boldsymbol{\beta}}\)</span>, even when <span class="math inline">\(E(\varepsilon)=0\)</span></li>
<li>An LSE has infinite variance (and Gauss-Markov theorem does not hold for LSE)</li>
</ul>
</section><section id="modern-scenario-p1-n-1" class="slide level2">
<h1>Modern scenario: <span class="math inline">\(p+1 &gt; n\)</span></h1>
<p>In this scenario, we have a few choices:</p>
<ul>
<li>perform variable/model selection: select a few most relevant predictors to form a model and then apply LSE to estimate the model parameters</li>
<li>employ different estimation methods: use a different method (such as <em>shrinkage</em>) than LSE to estimate coefficients of predictors in a model (as a <em>bias-variance trade-off</em>)</li>
<li>use dimension reduction: projecting all predictors onto a smaller subspace and use transformed predictors to build a model</li>
</ul>
</section></section>
<section><section id="best-subset-selection" class="titleslide slide level1"><h1>Best subset selection</h1></section><section id="overview-1" class="slide level2">
<h1>Overview</h1>
<ul>
<li><p>Consider a linear model with <span class="math inline">\(p\)</span> predictors: <span class="math display">\[
Y=\beta_0+\beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_p X_p + \varepsilon
\]</span></p></li>
<li><p><em>Best subset selection</em> is a “brute-force” method that checks <em>each of the <span class="math inline">\(2^p\)</span> possible linear submodels</em> and picks the best one under some criterion</p></li>
<li><p>Best subset selection indeed gives the <em>best subset of predictors (in terms of linear model)</em> among all <span class="math inline">\(p\)</span> predictors under a criterion</p></li>
</ul>
</section><section id="criteria-for-subset-selection" class="slide level2">
<h1>Criteria for subset selection</h1>
<p>Some criteria for subset/variable selection:</p>
<ul>
<li>Mallow’s <span class="math inline">\(C_p\)</span></li>
<li>AIC (i.e., Akaike information criterion),</li>
<li>BIC (i.e., Bayesian information criterion)</li>
<li>Adjusted <span class="math inline">\(R^2\)</span></li>
<li>Cross-validated prediction error</li>
</ul>
</section><section id="implementation" class="slide level2">
<h1>Implementation</h1>
<p><img src="Alg6.1.png" width="85%" style="display: block; margin: auto;" /></p>
</section><section id="illustration-1" class="slide level2">
<h1>Illustration</h1>
<p><img src="fig6.1.png" width="90%" style="display: block; margin: auto;" /></p>
</section></section>
<section><section id="forwardbackwards-stepwise-selection" class="titleslide slide level1"><h1>Forward/backwards stepwise selection</h1></section><section id="overview-2" class="slide level2">
<h1>Overview</h1>
<p>Forward stepwise selection</p>
<ul>
<li>only fits <span class="math display">\[1+\sum_{k=0}^{p-1}\left(p-k\right)=1+2^{-1}p\left(p+1\right)\]</span> <em>linear submodels</em> out of a total of <span class="math inline">\(2^p\)</span> linear submodels</li>
<li>is not guaranteed to find the best model among all linear submodels</li>
<li>has much smaller computational intensity than best subset selection</li>
</ul>
</section><section id="implementation-1" class="slide level2">
<h1>Implementation</h1>
<p><img src="alg6_2.png" width="90%" style="display: block; margin: auto;" /></p>
</section><section id="illustration-2" class="slide level2">
<h1>Illustration</h1>
<p><img src="t6_1.png" width="90%" style="display: block; margin: auto;" /></p>
</section><section id="backwards-stepwise-selection" class="slide level2">
<h1>Backwards stepwise selection</h1>
<p><img src="alg6_3.png" width="90%" style="display: block; margin: auto;" /></p>
</section></section>
<section><section id="choosing-the-optimal-model" class="titleslide slide level1"><h1>Choosing the optimal model</h1></section><section id="general-principle" class="slide level2">
<h1>General principle</h1>
<p>For best subset, forward stepwise, and backwards stepwise selections, <em>we need to select a best model from the best submodels</em>. However, neither <em>training</em> set RSS nor <em>training</em> set <span class="math inline">\(R^{2}\)</span> can be used for this purpose since</p>
<ul>
<li>neither ensures good predictive performance in terms of test error of the resultant model</li>
<li>either tends to pick a model that has the largest possible size in terms of the number of parameters</li>
</ul>
<p>So, a practical way to select a single best model is to <strong>balance the RSS on the training error and the model size</strong></p>
</section><section id="four-methods" class="slide level2">
<h1>Four methods</h1>
<p>Four methods to choose the optimal model:</p>
<ul>
<li>Mallow’s <span class="math inline">\(C_p\)</span></li>
<li>Akaike information criterion</li>
<li>Bayesian information criterion</li>
<li>Cross-validation</li>
</ul>
</section><section id="mallows-c_p" class="slide level2">
<h1>Mallow’s <span class="math inline">\(C_p\)</span></h1>
<p>Mallow’s</p>
<span class="math display">\[\begin{equation}
C_{p}=\frac{1}{n}\left( \textrm{RSS}+2d\hat{\sigma}^{2}\right)
\end{equation}\]</span>
<ul>
<li><span class="math inline">\(d\)</span> is the number of predictors in the model</li>
<li>Typically <span class="math inline">\(\hat{\sigma}^{2}\)</span>, an estimate of <span class="math inline">\(\sigma^2=\textrm{Var}(\varepsilon)\)</span>, is estimated using the full model containing all predictors</li>
</ul>
<p><em>Remark:</em> If <span class="math inline">\(\hat{\sigma}^{2}\)</span> is an unbiased estimate of <span class="math inline">\(\sigma^{2}\)</span>, then <span class="math inline">\(C_{p}\)</span> is an unbiased estimate of test MSE</p>
</section><section id="akaike-information-criterion" class="slide level2">
<h1>Akaike information criterion</h1>
<ul>
<li>The <em>Akaike information criterion (AIC)</em> is mainly used together with the <em>maximum likelihood method</em></li>
<li>For a linear model with Gaussian errors, the <em>maximum likelihood estimate (MLE)</em> is the same as the <em>least squares estimate (LSE)</em>. In this case, AIC is, up to an additive constant, given by <span class="math display">\[
\textrm{AIC}=\frac{1}{n\hat{\sigma}^{2}}\left(  \textrm{RSS}+2d\hat{\sigma}^{2}\right)
\]</span></li>
</ul>
</section><section id="bayesian-information-criterion" class="slide level2">
<h1>Bayesian information criterion</h1>
<ul>
<li>The <em>Bayesian information criterion (BIC)</em> is derived from a Bayesian perspective</li>
<li>For the least squares model with <span class="math inline">\(d\)</span> parameters, the BIC is, up to irrelevant constants, given by <span class="math display">\[
\textrm{BIC}=\frac{1}{n\hat{\sigma}^{2}}\left( \textrm{RSS}+d\hat{\sigma}^{2}\log n\right)
\]</span></li>
<li>BIC generally places a heavier penalty on models with many variables. For large <span class="math inline">\(n\)</span>, BIC is bigger than <span class="math inline">\(C_{p}\)</span></li>
</ul>
</section><section id="adjusted-r2" class="slide level2">
<h1>Adjusted <span class="math inline">\(R^{2}\)</span></h1>
<ul>
<li>The adjusted <span class="math inline">\(R^{2}\)</span> is given by <span class="math display">\[
\text{Adjusted }R^{2}=1-\frac{\textrm{RSS}/\left(  n-d-1\right)  }{\textrm{TSS}/\left(n-1\right)  }
\]</span></li>
<li><em>Unlike <span class="math inline">\(C_{p}\)</span>, AIC and BIC, for which a small value indicates a model with a low test error, a large value of adjusted <span class="math inline">\(R^{2}\)</span> indicates a model with a low test error</em></li>
</ul>
<p>The intuition behind the adjusted <span class="math inline">\(R^{2}\)</span> is that “once all of the correct variables have been included in the model, adding additional noise variables will lead to a very small decrease in RSS”</p>
</section><section id="recap" class="slide level2">
<h1>Recap</h1>
<p>Let <span class="math inline">\(d\)</span> be number of predictors in model, <span class="math inline">\(n\)</span> sample size, and <span class="math inline">\(\hat{\sigma}^{2}\)</span> an estimate of <span class="math inline">\(\sigma^2=\textrm{Var}(\varepsilon)\)</span>:</p>
<ul>
<li><p><span class="math inline">\(C_{p}=\frac{1}{n}\left( \textrm{RSS}+2d\hat{\sigma}^{2}\right)\)</span></p></li>
<li><p><span class="math inline">\(\textrm{AIC}=\frac{1}{n\hat{\sigma}^{2}}\left( RSS+2d\hat{\sigma}^{2}\right)\)</span></p></li>
<li><p><span class="math inline">\(\textrm{BIC}=\frac{1}{n\hat{\sigma}^{2}}\left( \textrm{RSS}+d\hat{\sigma}^{2}\log n\right)\)</span></p></li>
<li><p><span class="math inline">\(\text{Adjusted }R^{2}=1-\frac{\textrm{RSS}/\left( n-d-1\right) }{\textrm{TSS}/\left(n-1\right) }\)</span></p></li>
</ul>
<p>All formulae for <span class="math inline">\(C_{p}\)</span>, AIC and BIC are <em>for a linear model fit using least squares</em>; <span class="math inline">\(C_p\)</span>, AIC and BIC all have good theoretical justifications</p>
</section><section id="illustration-3" class="slide level2">
<h1>Illustration</h1>
<p><img src="fig6_2.png" width="90%" style="display: block; margin: auto;" /></p>
</section><section id="k-fold-cross-validation-1" class="slide level2">
<h1><span class="math inline">\(k\)</span>-fold cross-validation</h1>
<p>Recall CV for model selection:</p>
<ul>
<li>Obtain via cross-validation the estimated test error for each model <span class="math inline">\(M_l,l=1,\ldots,L\)</span></li>
<li>Pick the model that has the smallest estimated test MSE, i.e., pick the optimal model <span class="math inline">\(M^{\ast}\)</span> such that <span class="math display">\[\textrm{CV}(M^*)=\min_{1\le l \le L}\textrm{CV}(M_l)\]</span></li>
</ul>
</section><section id="k-fold-cross-validation-2" class="slide level2">
<h1><span class="math inline">\(k\)</span>-fold cross-validation</h1>
<p>The <span class="math inline">\(k\)</span>-fold CV for model <span class="math inline">\(M_l\)</span> is implemented as follows:</p>
<ul>
<li>Randomly splits the data set into <span class="math inline">\(k\)</span> groups, or “folds”, of approximately equal sizes</li>
<li>Pick a fold, say, folder <span class="math inline">\(j\)</span>, as the validation set (i.e., the “held-out” fold), fit the model on the remaining <span class="math inline">\(k-1\)</span> folds, and compute the mean squared error, <span class="math inline">\(\textrm{MSE}_{j}\)</span>, on the observations in the held-out fold</li>
<li>Do the above for all <span class="math inline">\(j,j=1,\ldots,k\)</span>, and estimate the test MSE of the model by <span class="math display">\[
\textrm{CV}({M_l})=\frac{1}{k}\sum_{j=1}^{k}\textrm{MSE}_{j}
\]</span></li>
</ul>
</section><section id="k-fold-cross-validation-3" class="slide level2">
<h1><span class="math inline">\(k\)</span>-fold cross-validation</h1>
<p>Guideline:</p>
<ul>
<li>Usually <span class="math inline">\(k=5\)</span> or <span class="math inline">\(10\)</span> is chosen, as these values have been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance</li>
</ul>
</section><section id="k-fold-cross-validation-4" class="slide level2">
<h1><span class="math inline">\(k\)</span>-fold cross-validation</h1>
<p><img src="fig6_3.png" width="90%" style="display: block; margin: auto;" /></p>
</section><section id="one-standard-error-rule" class="slide level2">
<h1>One-standard-error rule</h1>
<p>Different random splitting schemes often lead to differential optimal models. So,</p>
<ul>
<li><p>first, we can calculate the standard error of the estimated test MSE for each model size, by repeatedly validating ``the best model’’ of this model size</p></li>
<li><p>then select the smallest model for which the estimated test error is within one standard error of the lowest point on the front curve for the estimated MSEs of ``the best models’’</p></li>
</ul>
</section><section id="license-and-session-information" class="slide level2">
<h1>License and session Information</h1>
<p><a href="http://math.wsu.edu/faculty/xchen/stat412/LICENSE.html">License</a></p>
<section style="font-size: 0.75em;">
<pre class="r"><code>&gt; sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19043)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
[1] knitr_1.21

loaded via a namespace (and not attached):
 [1] compiler_3.5.0  magrittr_1.5    tools_3.5.0    
 [4] htmltools_0.3.6 revealjs_0.9    yaml_2.2.0     
 [7] Rcpp_1.0.3      stringi_1.2.4   rmarkdown_1.11 
[10] stringr_1.3.1   xfun_0.4        digest_0.6.18  
[13] evaluate_0.12  </code></pre>
</section>
</section></section>
    </div>
  </div>

  <script src="libs/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="libs/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display a presentation progress bar
        progress: true,
        // Display the page number of the current slide
        slideNumber: false,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: false,
        // Transition style
        transition: 'slide', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        chalkboard: {
        },

        keyboard: {
          67: function() { RevealChalkboard.toggleNotesCanvas() },    // toggle notes canvas when 'c' is pressed
          66: function() { RevealChalkboard.toggleChalkboard() }, // toggle chalkboard when 'b' is pressed
          46: function() { RevealChalkboard.clear() },    // clear chalkboard when 'DEL' is pressed
           8: function() { RevealChalkboard.reset() },    // reset chalkboard data on current slide when 'BACKSPACE' is pressed
          68: function() { RevealChalkboard.download() }, // downlad recorded chalkboard drawing when 'd' is pressed
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'libs/reveal.js-3.3.0.1/plugin/zoom-js/zoom.js', async: true },
          { src: 'libs/reveal.js-3.3.0.1/plugin/chalkboard/chalkboard.js', async: true },
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
